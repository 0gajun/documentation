---
title: "Archives sur AWS\_S3"
kind: Documentation
description: Transférez tous vos logs Datadog sur S3 pour les conserver à long terme.
aliases:
  - /fr/logs/s3/
  - /fr/logs/archives/
---
Ce guide décrit la marche à suivre pour transférer les logs que vous avez recueillis vers votre compartiment Amazon S3.

## Créer et configurer un compartiment S3

Accédez à votre [console AWS][1] et [créez un compartiment S3][2] vers lequel vos archives seront envoyées. Assurez-vous que votre compartiment n'est pas accessible au public.

Ensuite, autorisez Datadog à écrire des archives de logs dans votre compartiment S3. Ces autorisations peuvent être accordées directement depuis votre stratégie de compartiment ou en configurant une délégation de rôle.

{{< tabs >}}
{{% tab "Stratégie de compartiment" %}}

1. Modifiez votre compartiment pour autoriser l'accès en écriture seule à l'utilisateur AWS Datadog. Pour ce faire, modifiez les **autorisations** de votre compartiment et définissez la **stratégie de compartiment** avec le contenu suivant (remplacez `<NOM_DU_COMPARTIMENT>` par le nom de votre compartiment) :

    ```
    {
        "Version": "2012-10-17",
        "Statement": [
            {
                "Sid": "AllowDatadogArchivesUploader",
                "Effect": "Allow",
                "Principal": {
                    "AWS": "464622532012"
                },
                "Action": [
                    "s3:PutObject",
                    "s3:PutObjectAcl",
                    "s3:ListMultipartUploadParts",
                    "s3:AbortMultipartUpload"
                ],
                "Resource": "arn:aws:s3:::<MY_BUCKET_NAME>/*"
            }
        ]
    }
    ```

    {{< img src="logs/archives/log_archives_s3_iam_policy.png" alt="Stratégie IAM pour les archives S3" responsive="true" style="width:75%;">}}

2. Accédez à la [page Pipelines dans Datadog][1], puis sélectionnez l'option **Add archive** en bas de la page. Seuls les utilisateurs de Datadog bénéficiant des droits administrateur peuvent effectuer cette étape ainsi que la suivante.

3. Entrez le nom de votre compartiment. Facultatif : entrez un répertoire en préfixe pour tout le contenu de vos archives de logs. Enregistrez votre archive pour terminer.

    {{< img src="logs/archives/log_archives_s3_datadog_settings.png" alt="Définir les informations de votre compartiment S3 dans Datadog" responsive="true" style="width:75%;">}}

[1]: https://app.datadoghq.com/logs/pipelines
{{% /tab %}}

{{% tab "Délégation de rôle" %}}

**L'utilisation des délégations de rôle pour l'écrire d'archives de logs est en version bêta privée. Contactez [l'assistance Datadog][1] pour demander l'activation de cette fonctionnalité pour votre compte.**

1. Configurez [l'intégration AWS][2] pour le compte AWS associé à votre compartiment S3. Vous devrez [créer un rôle][3] utilisable par Datadog pour l'intégration à AWS Cloudwatch. 

2. Ajoutez l'instruction d'autorisation suivante aux stratégies IAM de votre rôle Datadog (assurez-vous de modifier les noms de compartiment et, si vous le souhaitez, de spécifier les chemins vers vos archives de logs). Les autorisations `GetObject` et `ListBucket` permettent de procéder à une [réintégration à partir des archives][4]. L'autorisation `PutObject` est suffisante pour l'envoi des archives.

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "DatadogUploadAndRehydrateLogArchives",
            "Effect": "Allow",
            "Action": [
                "s3:PutObject",
                "s3:GetObject"
            ],
            "Resource": [
                "arn:aws:s3:::<NOM_DU_BUCKET_1_/_CHEMIN_FACULTATIF_DU_BUCKET_1>/*",
                "arn:aws:s3:::<NOM_DU_BUCKET_2_/_CHEMIN_FACULTATIF_DU_BUCKET_2>/*"
            ]
        },
        {
            "Sid": "DatadogRehydrateLogArchivesListBucket",
            "Effect": "Allow",
            "Action": "s3:ListBucket",
            "Resource": [
                "arn:aws:s3:::<NOM_DU_BUCKET_1>",
                "arn:aws:s3:::<NOM_DU_BUCKET_2>"
            ]
        }
    ]
}
```

3. Accédez à la [page Pipelines dans Datadog][5], puis sélectionnez l'option **Add archive** en bas de la page. Seuls les utilisateurs de Datadog bénéficiant des droits administrateur peuvent effectuer cette étape ainsi que la suivante.

4. Sélectionnez le compte AWS et le rôle appropriés pour votre compartiment S3, puis saisissez le nom de votre compartiment. Vous avez la possibilité d'ajouter un répertoire comme préfixe vers lequel l'ensemble de vos archives de logs seront envoyées. Il ne vous reste plus qu'à enregistrer votre archive.

    {{< img src="logs/archives/log_archives_s3_datadog_settings_role_delegation.png" alt="Définir les informations de votre compartiment S3 dans Datadog" responsive="true" style="width:75%;">}}

[1]: /fr/help
[2]: https://app.datadoghq.com/account/settings#integrations/amazon-web-services
[3]: /fr/integrations/amazon_web_services/?tab=allpermissions#installation
[4]: /fr/logs/archives/rehydrating
[5]: https://app.datadoghq.com/logs/pipelines
{{% /tab %}}
{{< /tabs >}}

Dès que vos paramètres d'archivage ont été correctement configurés sur votre compte Datadog, tous les logs que Datadog ingère sont enrichis par vos pipelines de traitement avant d'être transférés vers votre compartiment S3 pour leur archivage.

Après avoir créé ou modifié vos paramètres d'archivage, il est néanmoins parfois nécessaire d'attendre quelques minutes avant la prochaine tentative d'importation des archives. Par conséquent, **attendez 15 minutes** avant de vérifier que les archives ont bien été importées vers votre compartiment S3 depuis votre compte Datadog.

## Format des archives S3

Les archives de logs que Datadog transmet à votre compartiment S3 sont au format JSON compressé (gzip). Les archives sont stockées sous le préfixe que vous avez indiqué (ou dans `/` si aucun préfixe n'a été défini) selon une structure de répertoire qui indique à quelle date et à quelle heure les fichiers d'archives ont été générés. La structure est la suivante :

`/my/s3/prefix/dt=20180515/hour=14/archive_143201.1234.7dq1a9mnSya3bFotoErfxl.json.gz`

Cette structure de répertoire vous permet d'interroger plus facilement vos archives de logs en fonction de leur date.

À l'intérieur du fichier JSON compressé, le contenu de chaque événement est formaté comme suit :

```
{
    "_id": "123456789abcdefg",
    "date": "2018-05-15T14:31:16.003Z",
    "host": "i-12345abced6789efg",
    "source": "source_name",
    "service": "service_name",
    "status": "status_level",
    "message": " ... log message content ... ",
    "attributes": { ... log attributes content ... }
}
```

**Remarque :** les archives incluent uniquement le contenu des logs, qui comprend le message, les attributs personnalisés et les attributs réservés de vos événements de log. Les tags des logs (métadonnées qui connectent vos données de log aux traces et aux métriques liées) ne sont pas inclus.

## Archives S3 multiples

Les administrateurs peuvent transmettre des logs spécifiques vers une archive en ajoutant une requête dans le champ `filter` de l'archive. Les logs sont envoyés dans la première archive filtrée à laquelle ils correspondent. Il est donc important d'organiser minutieusement vos archives.

Par exemple, si vous créez une première archive filtrée sur le tag `env:prod` et une deuxième archive sans filtre (l'équivalent de `*`), tous vos logs de production seront envoyés dans le premier chemin/compartiment S3 et toute le reste ira dans l'autre.

{{< img src="logs/archives/log_archives_s3_multiple.png" alt="Les logs sont envoyés dans la première archive filtrée à laquelle ils correspondent." responsive="true" style="width:75%;">}}

## Chiffrement côté serveur (SSE)

Pour ajouter le chiffrement côté serveur (SSE) à vos archives de logs S3, accédez à l'onglet **Properties** dans votre compartiment S3 et sélectionnez **Default Encryption**. Sélectionnez l'option `AES-256`, puis cliquez sur **Save**.

{{< img src="logs/archives/log_archives_s3_encryption.png" alt="Sélectionnez l'option AES-256 et cliquez sur Save." responsive="true" style="width:75%;">}}

[1]: https://s3.console.aws.amazon.com/s3
[2]: https://docs.aws.amazon.com/AmazonS3/latest/user-guide/create-bucket.html